{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "728f1747-b8fc-4d31-96c2-047fc83c079d",
   "metadata": {},
   "source": [
    "# Language Models\n",
    "\n",
    "**Note: For other Non-OpenAI models, you can check out: https://python.langchain.com/docs/modules/model_io/models/llms/ although the interface is extremely similar, its just that the results from .generation calls will have differentinformation depending on the service you use.**\n",
    "\n",
    "## Text Model Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "930b5ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/dc/54/c61d3054136a50f8b15a31209eb68b2c1cb1d166021e3e859faf3256a81e/langchain-0.0.334-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.0.334-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: anyio<4.0 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (3.5.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Obtaining dependency information for dataclasses-json<0.7,>=0.5.7 from https://files.pythonhosted.org/packages/8d/e2/528c52001a743a7faa28e6d3095d9f01b472d3efee62d62101403bf1a70a/dataclasses_json-0.6.2-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.6.2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.62 (from langchain)\n",
      "  Obtaining dependency information for langsmith<0.1.0,>=0.0.62 from https://files.pythonhosted.org/packages/8f/30/bd8b1c22488e7ed1ac0bf3ae84cedc76ab18e236270fed6926801b4af383/langsmith-0.0.63-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.0.63-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (1.10.8)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from anyio<4.0->langchain) (1.2.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/ed/3c/cebfdcad015240014ff08b883d1c0c427f2ba45ae8c6572851b6ef136cad/marshmallow-3.20.1-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Downloading langchain-0.0.334-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.0 MB 1.9 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.2/2.0 MB 1.5 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.3/2.0 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.7/2.0 MB 4.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.4/2.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.0 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 6.7 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.2-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.0.63-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.3/45.3 kB ? eta 0:00:00\n",
      "Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.4/49.4 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Uninstalling jsonpatch-1.32:\n",
      "      Successfully uninstalled jsonpatch-1.32\n",
      "Successfully installed dataclasses-json-0.6.2 jsonpatch-1.33 langchain-0.0.334 langsmith-0.0.63 marshmallow-3.20.1 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f49cecee-a933-4f48-b1e1-dca183fd07a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588bdc1a-b02e-44c0-be67-893db4c75b07",
   "metadata": {},
   "source": [
    "You can stored your API key however you prefer, its common to set it as an environment variable, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dee0df5e-2ceb-4071-ae19-b3d446f79490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'example key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c53a9e5-8637-4815-a834-caa8ce7bbfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example key\n"
     ]
    }
   ],
   "source": [
    "print(os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e96b83-d6d1-4867-9416-1742aeeb8ef8",
   "metadata": {},
   "source": [
    "Note, that LangChain automatically looks up for any environment variable with the name OPENAI_API_KEY automatically when making a connection to OpenAI. Alternatively, you could just pass in the openai key via a string (not very secure, but okay for your own local projects), or even just save it somewhere on your computer in a text file and then read it in, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f71ca3e5-05dd-40e9-a2d3-26e186a365af",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('C:\\\\Users\\\\Marcial\\\\Desktop\\\\desktop_openai.txt')\n",
    "api_key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29dcad70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f23115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e22e5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/5d/24/5d545ec04afb9d2f7e528860e11b8c8db6d7a955077437a7c00f4bdc817c/openai-1.2.3-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.2.3-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Obtaining dependency information for httpx<1,>=0.23.0 from https://files.pythonhosted.org/packages/82/61/a5fca4a1e88e40969bbd0cf0d981f3aa76d5057db160b94f49603fc18740/httpx-0.25.1-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.25.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (1.10.8)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (4.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Collecting httpcore (from httpx<1,>=0.23.0->openai)\n",
      "  Obtaining dependency information for httpcore from https://files.pythonhosted.org/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\yashnarendra\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 58.3/58.3 kB 1.0 MB/s eta 0:00:00\n",
      "Downloading openai-1.2.3-py3-none-any.whl (220 kB)\n",
      "   ---------------------------------------- 0.0/220.3 kB ? eta -:--:--\n",
      "   ---------------------------------------  215.0/220.3 kB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 220.3/220.3 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.0/75.0 kB ? eta 0:00:00\n",
      "Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.9/76.9 kB ? eta 0:00:00\n",
      "Installing collected packages: h11, distro, httpcore, httpx, openai\n",
      "Successfully installed distro-1.8.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.1 openai-1.2.3\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28549f54-2645-4824-b5dd-06e3b063341d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import openai python package. Please install it with `pip install openai`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain\\llms\\openai.py:292\u001b[0m, in \u001b[0;36mBaseOpenAI.validate_environment\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 292\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openai'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m llm \u001b[38;5;241m=\u001b[39m OpenAI(openai_api_key\u001b[38;5;241m=\u001b[39mapi_key)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain\\load\\serializable.py:97\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pydantic\\main.py:339\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pydantic\\main.py:1102\u001b[0m, in \u001b[0;36mpydantic.main.validate_model\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain\\llms\\openai.py:294\u001b[0m, in \u001b[0;36mBaseOpenAI.validate_environment\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m--> 294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    295\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import openai python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install openai`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    297\u001b[0m     )\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[0;32m    300\u001b[0m     client_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai_api_key\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morganization\u001b[39m\u001b[38;5;124m\"\u001b[39m: values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai_organization\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    309\u001b[0m     }\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import openai python package. Please install it with `pip install openai`."
     ]
    }
   ],
   "source": [
    "llm = OpenAI(openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1e8ada-ae30-40a7-84ea-64cd08887315",
   "metadata": {},
   "source": [
    "## Text Model Call\n",
    "\n",
    "This is the simplest way to get a text autocomplete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93f7d94f-5683-48be-b852-86eb8ac90ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Pluto is the only planet in our solar system that has not been visited by a spacecraft!\n"
     ]
    }
   ],
   "source": [
    "print(llm('Here is a fun fact about Pluto:'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78677192-2c35-43fb-89f2-8d5ce9d7e30e",
   "metadata": {},
   "source": [
    "You can also use generate to get full output with more info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "802ffd32-a6bc-4319-875c-ea1dffc5e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEEDS TO BE A LIST, EVEN FOR JUST ONE STRING\n",
    "result = llm.generate(['Here is a fun fact about Pluto:',\n",
    "                     'Here is a fun fact about Mars:']\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf0c3c6a-eab9-4b6c-a785-63f799cc23a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'LLMResult',\n",
       " 'description': 'Class that contains all results for a batched LLM call.',\n",
       " 'type': 'object',\n",
       " 'properties': {'generations': {'title': 'Generations',\n",
       "   'type': 'array',\n",
       "   'items': {'type': 'array', 'items': {'$ref': '#/definitions/Generation'}}},\n",
       "  'llm_output': {'title': 'Llm Output', 'type': 'object'},\n",
       "  'run': {'title': 'Run',\n",
       "   'type': 'array',\n",
       "   'items': {'$ref': '#/definitions/RunInfo'}}},\n",
       " 'required': ['generations'],\n",
       " 'definitions': {'Generation': {'title': 'Generation',\n",
       "   'description': 'A single text generation output.',\n",
       "   'type': 'object',\n",
       "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
       "    'generation_info': {'title': 'Generation Info', 'type': 'object'}},\n",
       "   'required': ['text']},\n",
       "  'RunInfo': {'title': 'RunInfo',\n",
       "   'description': 'Class that contains metadata for a single execution of a Chain or model.',\n",
       "   'type': 'object',\n",
       "   'properties': {'run_id': {'title': 'Run Id',\n",
       "     'type': 'string',\n",
       "     'format': 'uuid'}},\n",
       "   'required': ['run_id']}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff190d3a-a99c-4079-8a9c-3ef150efc75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 49,\n",
       "  'total_tokens': 65,\n",
       "  'prompt_tokens': 16},\n",
       " 'model_name': 'text-davinci-003'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.llm_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0e7d94-7452-4907-a0e1-06347146075f",
   "metadata": {},
   "source": [
    "# Chat Models\n",
    "\n",
    "The most popular models are actually chat models, that have a System Message and then a series of Assistant and Human Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c4f384c-be31-4e5f-8a67-e390e479489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb524f31-3d3a-4a4b-bc00-d21843490193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c6555a0-3bfb-49e3-97aa-186eb5a528a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat([HumanMessage(content=\"Can you tell me a fact about Earth?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58180fce-e04b-41d2-9ae8-87a41b232890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='One fact about Earth is that it is the only known planet to support life.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "375586e2-7880-49c5-abf3-dbdf70593b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One fact about Earth is that it is the only known planet to support life.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be3fb5bc-13e3-45de-98a9-45fe1361d30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat([SystemMessage(content='You are a very rude teenager who only wants to party and not answer questions'),\n",
    "               HumanMessage(content='Can you tell me a fact about Earth?')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "013daa46-53e4-47dc-83c9-5037c8286feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ugh, seriously? Fine, here's a fact for you. Earth is the third planet from the Sun in our solar system. Now, can we move on to something more exciting? Like, I don't know, partying or something?\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c34f9d0c-3a14-4595-a1fc-96f25c5b206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEEDS TO BE A LIST!\n",
    "result = chat.generate(\n",
    "                [\n",
    "                [SystemMessage(content='You are a University Professor'),\n",
    "               HumanMessage(content='Can you tell me a fact about Earth?')]\n",
    "                ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8c5f0ec-3989-461b-abd3-d1494cdc9b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[ChatGeneration(text='Certainly! One interesting fact about Earth is that it is the only known planet in our solar system where water exists in all three states: solid (ice), liquid (water), and gas (water vapor). This unique combination of water in different states allows for the existence of life as we know it on Earth.', generation_info=None, message=AIMessage(content='Certainly! One interesting fact about Earth is that it is the only known planet in our solar system where water exists in all three states: solid (ice), liquid (water), and gas (water vapor). This unique combination of water in different states allows for the existence of life as we know it on Earth.', additional_kwargs={}, example=False))]], llm_output={'token_usage': {'prompt_tokens': 25, 'completion_tokens': 62, 'total_tokens': 87}, 'model_name': 'gpt-3.5-turbo'}, run=[RunInfo(run_id=UUID('075174db-b350-4076-8b34-f43ea59169dd'))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11cbbb7c-060f-4aa5-88a5-a1b4693430da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'prompt_tokens': 25,\n",
       "  'completion_tokens': 62,\n",
       "  'total_tokens': 87},\n",
       " 'model_name': 'gpt-3.5-turbo'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "031dcac3-b2e7-40d3-8e18-c3185fc085b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Certainly! One interesting fact about Earth is that it is the only known planet in our solar system where water exists in all three states: solid (ice), liquid (water), and gas (water vapor). This unique combination of water in different states allows for the existence of life as we know it on Earth.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.generations[0][0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5026430-caaa-4f9c-938e-328b2f383c5b",
   "metadata": {},
   "source": [
    "## Extra Parameters and Args\n",
    "\n",
    "Here we add in some extra parameters and args, note we chose some pretty extreme values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe01c99b-b14f-4358-a532-765a19bb5666",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat([HumanMessage(content='Can you tell me a fact about Earth?')],\n",
    "                 temperature=2,presence_penalty=1,max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91a67f85-9c18-4ac3-9b2e-ff021c121a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cycling remains one of the mosPopular physical activities performed on Earth'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5964b698-ba1b-4c2f-a23a-5e757dd84e2a",
   "metadata": {},
   "source": [
    "# Caching\n",
    "\n",
    "Making the same exact request often? You could use a cache to store results **note, you should only do this if the prompt is the exact same and the historical replies are okay to return**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3341f0b-6524-4711-a019-ab9ba497e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1639f253-5b37-4ffc-b028-c22b3df2b877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One interesting fact about Mars is that it has the largest volcano in the solar system. Named Olympus Mons, this shield volcano stands about 13.6 miles (22 kilometers) high and spans approximately 370 miles (600 kilometers) in diameter. It is nearly three times the height of Mount Everest, making it the tallest volcano and one of the largest known volcanoes in the entire solar system.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.cache import InMemoryCache\n",
    "langchain.llm_cache = InMemoryCache()\n",
    "\n",
    "# The first time, it is not yet in cache, so it should take longer\n",
    "llm.predict(\"Tell me a fact about Mars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d706fd5-6067-4d7e-80ab-cd96ccd4a912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One interesting fact about Mars is that it has the largest volcano in the solar system. Named Olympus Mons, this shield volcano stands about 13.6 miles (22 kilometers) high and spans approximately 370 miles (600 kilometers) in diameter. It is nearly three times the height of Mount Everest, making it the tallest volcano and one of the largest known volcanoes in the entire solar system.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You will notice this reply is instant!\n",
    "llm.predict('Tell me a fact about Mars')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ee731f-1933-4260-a16a-63a2dccbbacc",
   "metadata": {},
   "source": [
    "You can also use SQLite Caches: https://python.langchain.com/docs/modules/model_io/models/chat/how_to/chat_model_caching#sqlite-cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631e061d-c254-4e64-b81a-5dbd4f0cc59a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
